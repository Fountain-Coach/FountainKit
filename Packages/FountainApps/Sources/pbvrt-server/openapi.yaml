openapi: 3.1.0
info:
  title: Prompt‑Bound Visual Regression Testing API (PB‑VRT)
  version: "1.0.0"
  summary: API for prompt-first baselines, probe-backed comparisons, and drift reporting for MIDI 2.0–driven GUIs.
  description: |
    Mirror of curated spec at Packages/FountainSpecCuration/openapi/v1/pb-vrt.yml.
    Update curated first; keep this copy in sync for generator.

servers:
  - url: /pb-vrt
    description: Local server (relative)

tags:
  - name: Prompts
  - name: Baselines
  - name: Compare
  - name: Probes
  - name: Vision
  - name: Audio

paths:
  /prompts:
    post:
      tags: [Prompts]
      operationId: registerPrompt
      summary: Register a prompt (immutable) and return its canonical hash.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Prompt'
      responses:
        '201':
          description: Prompt registered
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PromptRef'
        '409':
          description: Prompt already exists (id/hash conflict)

  /prompts/{id}:
    get:
      tags: [Prompts]
      operationId: getPrompt
      summary: Fetch a prompt by id
      parameters:
        - in: path
          name: id
          required: true
          schema: { type: string }
      responses:
        '200':
          description: Prompt
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Prompt'
        '404':
          description: Not found

  /baselines:
    post:
      tags: [Baselines]
      operationId: createBaseline
      summary: Create a baseline from a prompt + MIDI sequence + viewport; returns baseline id and artifact URIs.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BaselineInit'
      responses:
        '201':
          description: Baseline created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BaselineRef'

  /baselines/{id}:
    get:
      tags: [Baselines]
      operationId: getBaseline
      summary: Get baseline metadata (artifact links, probe versions, hashes)
      parameters:
        - in: path
          name: id
          required: true
          schema: { type: string }
      responses:
        '200':
          description: Baseline metadata
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Baseline'
        '404':
          description: Not found

  /compare:
    post:
      tags: [Compare]
      operationId: compareCandidate
      summary: Compare a newly rendered candidate against a stored baseline (pixel, SSIM, embeddings, prompt drift).
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselineId, candidatePng]
              properties:
                baselineId:
                  type: string
                candidatePng:
                  type: string
                  format: binary
                embeddingBackend:
                  type: string
                  enum: [featurePrint, coreML]
                  default: featurePrint
      responses:
        '200':
          description: Drift report
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DriftReport'

  /probes/embedding/compare:
    post:
      tags: [Probes]
      operationId: compareEmbeddingAdhoc
      summary: Compare two images via EmbeddingProbe without a baseline (ad‑hoc).
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselinePng, candidatePng]
              properties:
                baselinePng: { type: string, format: binary }
                candidatePng: { type: string, format: binary }
                backend:
                  type: string
                  enum: [featurePrint, coreML]
                  default: featurePrint
      responses:
        '200':
          description: Embedding comparison result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingResult'

  /probes/saliency/compare:
    post:
      tags: [Probes, Vision]
      operationId: compareSaliencyWeighted
      summary: Compare two images using a saliency-weighted metric and return saliency maps and weighted scores.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselinePng, candidatePng]
              properties:
                baselinePng: { type: string, format: binary }
                candidatePng: { type: string, format: binary }
      responses:
        '200':
          description: Saliency-weighted comparison result
          content:
            application/json:
              schema: { $ref: '#/components/schemas/SaliencyCompareResult' }

  /probes/align:
    post:
      tags: [Probes, Vision]
      operationId: alignImages
      summary: Estimate alignment transform and return post-alignment drift.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselinePng, candidatePng]
              properties:
                baselinePng: { type: string, format: binary }
                candidatePng: { type: string, format: binary }
      responses:
        '200':
          description: Alignment result and drift
          content:
            application/json:
              schema: { $ref: '#/components/schemas/AlignResult' }

  /probes/ocr/recognize:
    post:
      tags: [Probes, Vision]
      operationId: ocrRecognize
      summary: Recognize text lines and boxes for layout invariants.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [imagePng]
              properties:
                imagePng: { type: string, format: binary }
      responses:
        '200':
          description: OCR result
          content:
            application/json:
              schema: { $ref: '#/components/schemas/OCRResult' }

  /probes/contours:
    post:
      tags: [Probes, Vision]
      operationId: detectContours
      summary: Detect contours and report spacing statistics.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [imagePng]
              properties:
                imagePng: { type: string, format: binary }
      responses:
        '200':
          description: Contours and spacing summary
          content:
            application/json:
              schema: { $ref: '#/components/schemas/ContoursResult' }

  /probes/barcodes:
    post:
      tags: [Probes, Vision]
      operationId: detectBarcodes
      summary: Decode barcodes/QR codes for run linkage.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [imagePng]
              properties:
                imagePng: { type: string, format: binary }
      responses:
        '200':
          description: Decoded barcode payloads
          content:
            application/json:
              schema: { $ref: '#/components/schemas/BarcodesResult' }

  /probes/audio/embedding/compare:
    post:
      tags: [Probes, Audio]
      operationId: compareAudioEmbedding
      summary: Compare two audio files using an embedding backend (cosine distance).
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselineWav, candidateWav]
              properties:
                baselineWav: { type: string, format: binary }
                candidateWav: { type: string, format: binary }
                backend:
                  type: string
                  enum: [yamnet, coreml]
                  default: yamnet
      responses:
        '200':
          description: Audio embedding comparison
          content:
            application/json:
              schema: { $ref: '#/components/schemas/AudioEmbeddingResult' }

  /probes/audio/spectrogram/compare:
    post:
      tags: [Probes, Audio]
      operationId: compareSpectrogram
      summary: Compare Mel/STFT spectrograms (L2, log‑spectral distance, SSIM).
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselineWav, candidateWav]
              properties:
                baselineWav: { type: string, format: binary }
                candidateWav: { type: string, format: binary }
      responses:
        '200':
          description: Spectrogram comparison result
          content:
            application/json:
              schema: { $ref: '#/components/schemas/SpectrogramCompareResult' }

  /probes/audio/onsets:
    post:
      tags: [Probes, Audio]
      operationId: detectOnsets
      summary: Detect onsets and estimate tempo.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [wav]
              properties:
                wav: { type: string, format: binary }
      responses:
        '200':
          description: Onsets and tempo
          content:
            application/json:
              schema: { $ref: '#/components/schemas/OnsetsResult' }

  /probes/audio/pitch:
    post:
      tags: [Probes, Audio]
      operationId: analyzePitch
      summary: Estimate f0 contour and pitch statistics.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [wav]
              properties:
                wav: { type: string, format: binary }
      responses:
        '200':
          description: Pitch analysis
          content:
            application/json:
              schema: { $ref: '#/components/schemas/PitchResult' }

  /probes/audio/loudness:
    post:
      tags: [Probes, Audio]
      operationId: analyzeLoudness
      summary: Compute RMS envelope and loudness statistics.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [wav]
              properties:
                wav: { type: string, format: binary }
      responses:
        '200':
          description: Loudness analysis
          content:
            application/json:
              schema: { $ref: '#/components/schemas/LoudnessResult' }

  /probes/audio/alignment:
    post:
      tags: [Probes, Audio]
      operationId: analyzeAlignment
      summary: Estimate offset/drift between baseline and candidate audio.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [baselineWav, candidateWav]
              properties:
                baselineWav: { type: string, format: binary }
                candidateWav: { type: string, format: binary }
      responses:
        '200':
          description: Alignment analysis
          content:
            application/json:
              schema: { $ref: '#/components/schemas/AlignmentResult' }

  /probes/audio/transcribe:
    post:
      tags: [Probes, Audio]
      operationId: transcribeAudio
      summary: Transcribe speech audio (best‑effort).
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required: [wav]
              properties:
                wav: { type: string, format: binary }
                language: { type: string, default: en-US }
      responses:
        '200':
          description: Transcript
          content:
            application/json:
              schema: { $ref: '#/components/schemas/TranscriptResult' }

components:
  schemas:
    Prompt:
      type: object
      required: [id, text, modality]
      properties:
        id: { type: string }
        text: { type: string }
        tags:
          type: array
          items: { type: string }
        modality:
          type: string
          enum: [visual]
        embedding_model:
          type: string
          description: Optional text embedding model id (for prompt‑visual drift)
        hash:
          type: string
          description: Canonical content hash (sha256:<hex>)
    PromptRef:
      type: object
      required: [id, hash]
      properties:
        id: { type: string }
        hash: { type: string }
        uri: { type: string }
    Viewport:
      type: object
      required: [width, height, scale]
      properties:
        width: { type: integer }
        height: { type: integer }
        scale: { type: number, format: float }
    UMPPacket:
      type: object
      description: MIDI 2.0 Universal MIDI Packet (packed 32‑bit words as hex)
      required: [word0]
      properties:
        word0: { type: string, pattern: '^[0-9A-Fa-f]{8}$' }
        word1: { type: string, pattern: '^[0-9A-Fa-f]{8}$' }
        word2: { type: string, pattern: '^[0-9A-Fa-f]{8}$' }
        word3: { type: string, pattern: '^[0-9A-Fa-f]{8}$' }
    MIDISequence:
      type: object
      required: [sequenceID, packets]
      properties:
        sequenceID: { type: string }
        packets:
          type: array
          items: { $ref: '#/components/schemas/UMPPacket' }
        channel: { type: integer, minimum: 1, maximum: 16 }
        deviceName: { type: string }
        hash:
          type: string
          description: Hash over packet bytes (sha256:<hex>)
    BaselineInit:
      type: object
      required: [promptId, viewport, midiSequence]
      properties:
        promptId: { type: string }
        viewport: { $ref: '#/components/schemas/Viewport' }
        delayBeforeCapture:
          type: number
          format: float
          default: 0.25
        midiSequence: { $ref: '#/components/schemas/MIDISequence' }
        rendererVersion: { type: string }
        probes:
          type: object
          properties:
            embeddingBackend:
              type: string
              enum: [featurePrint, coreML]
              default: featurePrint
    BaselineRef:
      type: object
      required: [baselineId, uri]
      properties:
        baselineId: { type: string }
        uri: { type: string }
    Baseline:
      type: object
      required: [baselineId, promptRef, viewport, rendererVersion, artifacts]
      properties:
        baselineId: { type: string }
        promptRef: { $ref: '#/components/schemas/PromptRef' }
        viewport: { $ref: '#/components/schemas/Viewport' }
        rendererVersion: { type: string }
        midiSequence: { $ref: '#/components/schemas/MIDISequence' }
        probes:
          type: object
          properties:
            embeddingBackend:
              type: string
              enum: [featurePrint, coreML]
        artifacts:
          type: object
          properties:
            baselinePng: { type: string }
            embeddingJson: { type: string }
            midiUmp: { type: string }
    EmbeddingResult:
      type: object
      required: [metricName, value, backend, model, durationMs]
      properties:
        metricName:
          type: string
          enum: [featureprint_distance, clip_cosine]
        value: { type: number, format: float }
        backend:
          type: string
          enum: [featurePrint, coreML]
        model: { type: string }
        durationMs: { type: number, format: float }
    DriftReport:
      type: object
      required: [baselineId, metrics, pass]
      properties:
        baselineId: { type: string }
        metrics:
          type: object
          properties:
            pixel_l1: { type: number, format: float }
            ssim: { type: number, format: float }
            featureprint_distance: { type: number, format: float }
            clip_cosine: { type: number, format: float }
            prompt_cosine: { type: number, format: float }
        pass: { type: boolean }
        artifacts:
          type: object
          properties:
            candidatePng: { type: string }
            deltaPng: { type: string }
        timestamps:
          type: object
          properties:
            baseline: { type: string, format: date-time }
            run: { type: string, format: date-time }

    SaliencyCompareResult:
      type: object
      properties:
        weighted_l1: { type: number, format: float }
        weighted_ssim: { type: number, format: float }
        artifacts:
          type: object
          properties:
            baselineSaliency: { type: string }
            candidateSaliency: { type: string }
            weightedDelta: { type: string }

    Transform2D:
      type: object
      properties:
        dx: { type: number, format: float }
        dy: { type: number, format: float }
        scale: { type: number, format: float }
        rotationDeg: { type: number, format: float }
        homography:
          type: array
          items: { type: number, format: float }
          minItems: 9
          maxItems: 9

    AlignResult:
      type: object
      properties:
        transform: { $ref: '#/components/schemas/Transform2D' }
        postAlignDriftPx: { type: number, format: float }
        artifacts:
          type: object
          properties:
            alignedCandidatePng: { type: string }

    OCRLine:
      type: object
      properties:
        text: { type: string }
        bbox:
          type: object
          properties: { x: {type:number}, y: {type:number}, w: {type:number}, h: {type:number} }

    OCRResult:
      type: object
      properties:
        lineCount: { type: integer }
        wrapColumnMedian: { type: number, format: float }
        lines:
          type: array
          items: { $ref: '#/components/schemas/OCRLine' }

    ContoursResult:
      type: object
      properties:
        spacingMeanPx: { type: number, format: float }
        spacingStdPx: { type: number, format: float }
        count: { type: integer }
        artifacts:
          type: object
          properties:
            contoursImage: { type: string }

    BarcodesResult:
      type: object
      properties:
        payloads:
          type: array
          items: { type: string }
        types:
          type: array
          items: { type: string }

    AudioEmbeddingResult:
      type: object
      required: [metricName, value, backend, model, durationMs]
      properties:
        metricName:
          type: string
          enum: [audio_embedding_cosine]
        value: { type: number, format: float }
        backend:
          type: string
          enum: [yamnet, coreml]
        model: { type: string }
        durationMs: { type: number, format: float }

    SpectrogramCompareResult:
      type: object
      properties:
        l2: { type: number, format: float }
        lsd_db: { type: number, format: float }
        ssim: { type: number, format: float }
        artifacts:
          type: object
          properties:
            baselineSpecPng: { type: string }
            candidateSpecPng: { type: string }
            deltaSpecPng: { type: string }

    OnsetsResult:
      type: object
      properties:
        onsetsSec:
          type: array
          items: { type: number, format: float }
        tempoBpm: { type: number, format: float }

    PitchResult:
      type: object
      properties:
        f0Hz:
          type: array
          items: { type: number, format: float }
        centsErrorMean: { type: number, format: float }

    LoudnessResult:
      type: object
      properties:
        rms:
          type: array
          items: { type: number, format: float }
        meanDb: { type: number, format: float }
        maxDb: { type: number, format: float }

    AlignmentResult:
      type: object
      properties:
        offsetMs: { type: number, format: float }
        driftMs: { type: number, format: float }

    TranscriptResult:
      type: object
      properties:
        transcript: { type: string }
        language: { type: string }
