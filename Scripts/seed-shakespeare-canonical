#!/usr/bin/env python3
import argparse, json, os, sys, subprocess
from pathlib import Path
from urllib.parse import urlparse

def http_json(method, url, obj, timeout=60):
    data = json.dumps(obj, ensure_ascii=False).encode('utf-8')
    out = subprocess.check_output([
        'curl','-sf','-X',method, url,
        '-H','Content-Type: application/json',
        '--data-binary','@-'
    ], input=data, timeout=timeout)
    return json.loads(out.decode('utf-8'))

def post_json(url, obj):
    return http_json('POST', url, obj)

def pick_source(canon_list):
    # Prefer MIT when present
    mit = next((c for c in canon_list if c.get('name','').lower().find('mit') >= 0), None)
    if mit: return mit
    return canon_list[0] if canon_list else None

def main():
    ap = argparse.ArgumentParser(description='Seed canonical Shakespeare edition into FountainStore via Semantic Browser analysis + Persist API')
    ap.add_argument('--mapping', default='Configuration/shakespeare-canonical.json')
    ap.add_argument('--sb-url', default=os.environ.get('SEMANTIC_BROWSER_URL','http://127.0.0.1:8007'))
    ap.add_argument('--persist-url', default=os.environ.get('PERSIST_URL','http://127.0.0.1:8005'))
    ap.add_argument('--corpus', default='shakespeare-canonical')
    ap.add_argument('--limit', type=int, default=0, help='Optional limit for quick runs')
    args = ap.parse_args()

    root = Path.cwd()
    mapping = json.loads((root/args.mapping).read_text(encoding='utf-8'))
    items = mapping[:args.limit] if args.limit and args.limit > 0 else mapping

    # Ensure corpus exists
    try:
        post_json(f"{args.persist_url.rstrip('/')}/corpora", {"corpusId": args.corpus})
    except subprocess.CalledProcessError:
        pass

    for it in items:
        title = it['title']
        canon = pick_source(it.get('canonical',[]))
        if not canon:
            print(f"[seed] WARN: no canonical source for {title}", file=sys.stderr)
            continue
        url = canon['url']
        print(f"[seed] {title} ‚Üê {url}")
        # 1) Ask Semantic Browser to browse + analyze
        browse_req = {
            "url": url,
            "wait": {"strategy": "networkIdle", "networkIdleMs": 500, "maxWaitMs": 15000},
            "mode": "standard"
        }
        resp = post_json(f"{args.sb_url.rstrip('/')}/v1/browse", browse_req)
        analysis = resp.get('analysis')
        if not analysis:
            print(f"[seed] ERROR: no analysis for {title}", file=sys.stderr)
            continue
        env = analysis.get('envelope', {})
        page_id = env.get('id') or it.get('slug')
        page_url = env.get('source',{}).get('uri') or url
        host = urlparse(page_url).netloc or 'canonical'
        # Title: prefer mapping title; else first heading block
        blocks = analysis.get('blocks', [])
        heading = next((b.get('text') for b in blocks if (b.get('kind') or '').lower() == 'heading'), None)
        page_title = title or heading or host
        # 2) Upsert Page
        page = {"corpusId": args.corpus, "pageId": page_id, "url": page_url, "host": host, "title": page_title}
        post_json(f"{args.persist_url.rstrip('/')}/corpora/{args.corpus}/pages", page)
        # 3) Upsert Segments (all blocks as paragraph/heading/code/caption/table JSON)
        for b in blocks:
            seg_id = b.get('id')
            kind = (b.get('kind') or 'paragraph')
            text = b.get('text') or ''
            # Serialise tables inline as JSON lines when present
            if not text and b.get('table') is not None:
                text = json.dumps(b['table'], ensure_ascii=False)
            if not seg_id:
                continue
            seg = {"corpusId": args.corpus, "segmentId": seg_id, "pageId": page_id, "kind": kind, "text": text}
            try:
                post_json(f"{args.persist_url.rstrip('/')}/corpora/{args.corpus}/segments", seg)
            except subprocess.CalledProcessError:
                # Skip on collision
                pass
        # 4) Add an analysis summary line
        summ = analysis.get('summaries',{})
        abstract = summ.get('abstract') or ''
        summary_line = f"seeded canonical from {host} {url}"
        if abstract:
            summary_line = abstract[:200]
        try:
            post_json(f"{args.persist_url.rstrip('/')}/corpora/{args.corpus}/analyses", {"corpusId": args.corpus, "analysisId": f"seed:{page_id}", "pageId": page_id, "summary": summary_line})
        except subprocess.CalledProcessError:
            pass

    print(f"[seed] Completed seeding corpus '{args.corpus}'")

if __name__ == '__main__':
    main()
